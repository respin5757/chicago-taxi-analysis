{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chicago Taxi Data Analysis (2023)\n",
        "\n",
        "## Dataset Overview\n",
        "\n",
        "This analysis focuses on taxi trips in Chicago during the year 2023, using data reported to the City of Chicago in its role as a regulatory agency. The dataset includes detailed trip information such as start and end times, trip distances, fares, and payment methods.\n",
        "\n",
        "### Privacy Considerations\n",
        "- **Taxi ID**: A consistent identifier is used for each taxi medallion number, but the actual medallion number is not shown to protect privacy.\n",
        "- **Census Tracts**: Location details such as pickup and drop-off Census Tracts are suppressed in some cases.\n",
        "- **Timestamp Rounding**: Trip start and end times are rounded to the nearest 15 minutes.\n",
        "\n",
        "### Limitations\n",
        "Not all trips are reported due to the data collection process; however, the City of Chicago believes the dataset represents the majority of trips.\n",
        "\n",
        "For more details about the dataset and its creation, see [this page](https://console.cloud.google.com/marketplace/product/city-of-chicago-public-data/chicago-taxi-trips?hl=en&organizationId=0&project=velvety-outcome-444601-r0) on the City of Chicago's blog.\n",
        "\n",
        "# 1. Load Data\n",
        "\n",
        "To start the analysis, we load the dataset from Google Drive where the monthly taxi trip CSV files are stored. The Google Drive plugin is used to access and download the data directly into the Jupyter environment.\n",
        "\n",
        "### Steps:\n",
        "1. Authenticate access to Google Drive.\n",
        "2. Download the monthly CSV files into the working directory.\n",
        "3. Load the CSV files into a Pandas DataFrame for processing."
      ],
      "metadata": {
        "id": "OhK4B2k5iJwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the folder containing the files\n",
        "folder_path = '/content/drive/My Drive/Chicago Taxi Data/'\n",
        "\n",
        "# List all CSV files in the folder\n",
        "file_paths = glob.glob(os.path.join(folder_path, '*.csv'))\n",
        "\n",
        "# Load each file into a DataFrame and combine them\n",
        "dataframes = []\n",
        "for file_path in file_paths:\n",
        "    print(f\"Loading data from {file_path}...\")\n",
        "    df = pd.read_csv(file_path)\n",
        "    dataframes.append(df)\n",
        "\n",
        "# Combine all months into one DataFrame\n",
        "all_data = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Display basic information about the combined data\n",
        "print(\"Data loaded successfully. Preview:\")\n",
        "print(all_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbxGN6fIiR1e",
        "outputId": "8eb7c532-56b7-418d-a700-5e7e7578261e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-jan2023.csv...\n",
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-feb2023.csv...\n",
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-mar2023.csv...\n",
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-apr2023.csv...\n",
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-may2023.csv...\n",
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-jun2023.csv...\n",
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-jul2023.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-59bd3cead216>:19: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-aug2023.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-59bd3cead216>:19: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-sep2023.csv...\n",
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-oct2023.csv...\n",
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-nov2023.csv...\n",
            "Loading data from /content/drive/My Drive/Chicago Taxi Data/chicago-taxi-dec2023.csv...\n",
            "Data loaded successfully. Preview:\n",
            "                                 unique_key  \\\n",
            "0  ea138d778cb63034cabcbb81031b7946a513e08b   \n",
            "1  008901346b4899be1caacc775e605d0b01ce6ea9   \n",
            "2  063f013869c8293a083c6b9d0f446055e539a9a5   \n",
            "3  11cec01787dab2f4c875356b74eecbaae6a06431   \n",
            "4  29767d8c282e30f4c1c23fe0a8f14424d4567918   \n",
            "\n",
            "                                             taxi_id     trip_start_timestamp  \\\n",
            "0  82436a5c2f9503cc461215c839f24fa16fa7f02d9390bb...  2023-01-31 10:45:00 UTC   \n",
            "1  ed17822a864c82f0ac8c3110918dacfa804f66b06d9668...  2023-01-18 19:45:00 UTC   \n",
            "2  7ed122481c0964a5555309bf4696e25bbf7def086d7ecb...  2023-01-27 22:00:00 UTC   \n",
            "3  98a68977816db353e8cb08eaff4e3371612966c57d4afc...  2023-01-01 20:00:00 UTC   \n",
            "4  4985679c5d03d534d606702c915a7c74f83edb456f886e...  2023-01-05 09:15:00 UTC   \n",
            "\n",
            "        trip_end_timestamp  trip_seconds  trip_miles  pickup_census_tract  \\\n",
            "0  2023-02-01 10:45:00 UTC       86340.0         0.0         1.703198e+10   \n",
            "1  2023-01-18 19:45:00 UTC         234.0         0.0                  NaN   \n",
            "2  2023-01-27 22:00:00 UTC         240.0         0.0                  NaN   \n",
            "3  2023-01-01 20:30:00 UTC        1860.0        15.4                  NaN   \n",
            "4  2023-01-05 09:15:00 UTC         420.0         1.6                  NaN   \n",
            "\n",
            "   dropoff_census_tract  pickup_community_area  dropoff_community_area  ...  \\\n",
            "0          1.703108e+10                   56.0                     8.0  ...   \n",
            "1                   NaN                    NaN                     NaN  ...   \n",
            "2                   NaN                    NaN                     NaN  ...   \n",
            "3                   NaN                    NaN                     NaN  ...   \n",
            "4                   NaN                    NaN                     NaN  ...   \n",
            "\n",
            "   extras  trip_total  payment_type                        company  \\\n",
            "0     0.0       46.20   Credit Card                     Globe Taxi   \n",
            "1     5.5       10.00          Cash                   City Service   \n",
            "2     0.0        6.25          Cash  Taxicab Insurance Agency, LLC   \n",
            "3     5.0       53.20   Credit Card            Top Cab Affiliation   \n",
            "4     0.0        7.75          Cash        Choice Taxi Association   \n",
            "\n",
            "   pickup_latitude pickup_longitude                      pickup_location  \\\n",
            "0        41.785999       -87.750934  POINT (-87.7509342894 41.785998518)   \n",
            "1              NaN              NaN                                  NaN   \n",
            "2              NaN              NaN                                  NaN   \n",
            "3              NaN              NaN                                  NaN   \n",
            "4              NaN              NaN                                  NaN   \n",
            "\n",
            "   dropoff_latitude  dropoff_longitude                      dropoff_location  \n",
            "0         41.892508         -87.626215  POINT (-87.6262149064 41.8925077809)  \n",
            "1               NaN                NaN                                   NaN  \n",
            "2               NaN                NaN                                   NaN  \n",
            "3               NaN                NaN                                   NaN  \n",
            "4               NaN                NaN                                   NaN  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) ETL (Extract, Transform, Load) and Data Segmentation\n",
        "\n",
        "We now perform data cleaning, transformations, and feature engineering on different segments of the data. Each segmentation targets a specific analytical goal. By creating separate, cleaned DataFrames for each segmentation, we ensure transformations don’t interfere with one another."
      ],
      "metadata": {
        "id": "fswQ8vpSIW3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Revenue and Profitability Analysis\n",
        "The goal of this segmentation is to understand the relationship between trip distance, time, and revenue. By calculating metrics like revenue per mile and revenue per minute, we can identify high-efficiency trips and explore profitability patterns. Additionally, tip percentages provide insights into customer tipping behavior.\n"
      ],
      "metadata": {
        "id": "x_WzCHd-wQNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the data for revenue and profitability analysis\n",
        "revenue_data = all_data.copy()\n",
        "\n",
        "# Remove rows with missing or zero values in critical columns\n",
        "revenue_data = revenue_data.dropna(subset=['trip_total', 'trip_miles', 'trip_seconds'])\n",
        "revenue_data = revenue_data[(revenue_data['trip_miles'] > 0) & (revenue_data['trip_total'] > 0)]\n",
        "\n",
        "# Remove outliers (e.g., trips with extremely high fares or distances)\n",
        "revenue_data = revenue_data[(revenue_data['trip_miles'] < 100) & (revenue_data['trip_total'] < 1000)]\n",
        "\n",
        "# Add new metrics\n",
        "revenue_data['revenue_per_mile'] = revenue_data['trip_total'] / revenue_data['trip_miles']\n",
        "revenue_data['revenue_per_minute'] = revenue_data['trip_total'] / (revenue_data['trip_seconds'] / 60)\n",
        "revenue_data['tip_percentage'] = (revenue_data['tips'] / revenue_data['fare']) * 100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ALL3ZR0wTqU",
        "outputId": "c1d115af-c10d-4c61-e8de-ade48782f96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-e1610ec035be>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  revenue_data['revenue_per_mile'] = revenue_data['trip_total'] / revenue_data['trip_miles']\n",
            "<ipython-input-2-e1610ec035be>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  revenue_data['revenue_per_minute'] = revenue_data['trip_total'] / (revenue_data['trip_seconds'] / 60)\n",
            "<ipython-input-2-e1610ec035be>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  revenue_data['tip_percentage'] = (revenue_data['tips'] / revenue_data['fare']) * 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Demand Patterns by Time and Location\n",
        "This segmentation focuses on identifying when and where demand is highest. By extracting time-based features (e.g., hour of day, day of week, month), we can uncover temporal trends in trip demand. This information helps highlight peak demand periods and geographic hotspots.\n"
      ],
      "metadata": {
        "id": "6BsEOB_9wX_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the data for demand patterns\n",
        "demand_data = all_data.copy()\n",
        "\n",
        "# Remove rows with missing or invalid timestamps\n",
        "demand_data = demand_data.dropna(subset=['trip_start_timestamp'])\n",
        "demand_data['trip_start_timestamp'] = pd.to_datetime(demand_data['trip_start_timestamp'])\n",
        "\n",
        "# Ensure valid latitude and longitude\n",
        "demand_data = demand_data.dropna(subset=['pickup_latitude', 'pickup_longitude'])\n",
        "demand_data = demand_data[(demand_data['pickup_latitude'].between(-90, 90)) &\n",
        "                          (demand_data['pickup_longitude'].between(-180, 180))]\n",
        "\n",
        "# Add new time-based metrics\n",
        "demand_data['hour_of_day'] = demand_data['trip_start_timestamp'].dt.hour\n",
        "demand_data['day_of_week'] = demand_data['trip_start_timestamp'].dt.day_name()\n",
        "demand_data['month'] = demand_data['trip_start_timestamp'].dt.month_name()\n"
      ],
      "metadata": {
        "id": "ogpswQYAwaLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Payment Method Analysis\n",
        "This segmentation explores how payment methods (e.g., cash vs. card) influence revenue and tipping behavior. By calculating average tips and revenue for each payment type, we can identify customer preferences and analyze how payment methods impact profitability.\n"
      ],
      "metadata": {
        "id": "75cWlUYcwh_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the data for payment method analysis\n",
        "payment_data = all_data.copy()\n",
        "\n",
        "# Remove rows with missing or invalid values\n",
        "payment_data = payment_data.dropna(subset=['payment_type', 'fare', 'tips'])\n",
        "payment_data = payment_data[payment_data['fare'] > 0]\n",
        "\n",
        "# Summarize payment-specific metrics\n",
        "payment_summary = payment_data.groupby('payment_type').agg({\n",
        "    'tips': 'mean',\n",
        "    'trip_total': 'sum',\n",
        "    'fare': 'mean'\n",
        "}).reset_index()\n",
        "payment_summary['avg_tip_percentage'] = (payment_summary['tips'] / payment_summary['fare']) * 100\n"
      ],
      "metadata": {
        "id": "lJuiP7P6wkBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Geospatial Trip Efficiency\n",
        "This segmentation examines how trip efficiency varies across different pickup and drop-off locations. Metrics like efficiency ratio (fare per mile) and trip duration in minutes help assess pricing fairness and profitability in different geographic areas.\n"
      ],
      "metadata": {
        "id": "g6X0XpmfwmCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the data for geospatial analysis\n",
        "geospatial_data = all_data.copy()\n",
        "\n",
        "# Remove rows with missing or invalid values\n",
        "geospatial_data = geospatial_data.dropna(subset=['trip_miles', 'fare', 'pickup_latitude', 'pickup_longitude'])\n",
        "geospatial_data = geospatial_data[(geospatial_data['trip_miles'] > 0) &\n",
        "                                  (geospatial_data['pickup_latitude'].between(-90, 90)) &\n",
        "                                  (geospatial_data['pickup_longitude'].between(-180, 180))]\n",
        "\n",
        "# Add geospatial metrics\n",
        "geospatial_data['efficiency_ratio'] = geospatial_data['fare'] / geospatial_data['trip_miles']\n",
        "geospatial_data['trip_duration_minutes'] = geospatial_data['trip_seconds'] / 60\n"
      ],
      "metadata": {
        "id": "qOSBPci2wnmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Temporal Revenue Trends\n",
        "This segmentation focuses on analyzing revenue patterns over time. By aggregating daily and hourly revenues, we can identify key trends and predict high-revenue periods. This is useful for understanding seasonal changes and operational planning.\n"
      ],
      "metadata": {
        "id": "lhjPRQ2cwrwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the data for temporal analysis\n",
        "temporal_data = all_data.copy()\n",
        "\n",
        "# Remove rows with missing or invalid values\n",
        "temporal_data = temporal_data.dropna(subset=['trip_start_timestamp', 'trip_total'])\n",
        "temporal_data['trip_start_timestamp'] = pd.to_datetime(temporal_data['trip_start_timestamp'])\n",
        "\n",
        "# Aggregate daily and hourly revenue\n",
        "temporal_data['trip_date'] = temporal_data['trip_start_timestamp'].dt.date\n",
        "daily_revenue = temporal_data.groupby('trip_date')['trip_total'].sum().reset_index()\n",
        "hourly_revenue = temporal_data.groupby(temporal_data['trip_start_timestamp'].dt.hour)['trip_total'].sum().reset_index()\n"
      ],
      "metadata": {
        "id": "HpzjPIgwwuBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Download Prepared Data\n",
        "\n",
        "After performing ETL and segmentation, we export the cleaned and enriched datasets for use in Tableau or other visualization tools.\n"
      ],
      "metadata": {
        "id": "j4xQq6thwzOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export each segmentation\n",
        "revenue_data.to_csv('/content/drive/My Drive/Revenue_Data.csv', index=False)\n",
        "demand_data.to_csv('/content/drive/My Drive/Demand_Data.csv', index=False)\n",
        "payment_summary.to_csv('/content/drive/My Drive/Payment_Summary.csv', index=False)\n",
        "geospatial_data.to_csv('/content/drive/My Drive/Geospatial_Data.csv', index=False)\n",
        "daily_revenue.to_csv('/content/drive/My Drive/Daily_Revenue.csv', index=False)\n",
        "hourly_revenue.to_csv('/content/drive/My Drive/Hourly_Revenue.csv', index=False)\n"
      ],
      "metadata": {
        "id": "x8sDKIxGw0JL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}